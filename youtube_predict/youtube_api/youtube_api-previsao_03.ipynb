{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modelo e dados carregados. Total de colunas em X_train: 110\n",
      "📊 Média de views dos últimos 10 vídeos: 39720\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# 🚀 Carregar o modelo treinado e as colunas do X_train\n",
    "modelo_rf = joblib.load(\"modelo_rf_otimizado.pkl\")  # Ajuste para o modelo correto se necessário\n",
    "X_train_columns = joblib.load(\"X_train_columns.pkl\")\n",
    "\n",
    "# Criar um DataFrame vazio com as colunas corretas\n",
    "X_train = pd.DataFrame(columns=X_train_columns)\n",
    "\n",
    "print(f\"✅ Modelo e dados carregados. Total de colunas em X_train: {len(X_train_columns)}\")\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# 🚀 Carregar df_videos salvo do treinamento\n",
    "df_videos = joblib.load(\"df_videos.pkl\")\n",
    "\n",
    "# 🚀 Calcular automaticamente a média de views dos últimos 10 vídeos\n",
    "media_views_ultimos_10 = df_videos[\"views\"].rolling(window=10, min_periods=1).mean().iloc[-1]\n",
    "\n",
    "print(f\"📊 Média de views dos últimos 10 vídeos: {int(media_views_ultimos_10)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀 Lista de palavras-chave do nicho (ajuste conforme necessário)\n",
    "palavras_chave_nicho = [\"treino\", \"hipertrofia\", \"massa muscular\", \"exercício\", \"dieta\", \"proteína\", \"suplemento\"]\n",
    "\n",
    "# 🚀 Criar uma função para contar palavras do nicho no título do novo vídeo\n",
    "def contar_palavras_nicho(titulo):\n",
    "    return sum(1 for palavra in palavras_chave_nicho if palavra in titulo.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# 🚀 Função para analisar a thumbnail localmente\n",
    "def analisar_thumbnail_local(caminho_imagem):\n",
    "    try:\n",
    "        # Carregar imagem\n",
    "        img = Image.open(caminho_imagem)\n",
    "        img_cv = np.array(img)\n",
    "\n",
    "        # Converter para escala de cinza\n",
    "        gray = cv2.cvtColor(img_cv, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Calcular brilho (média dos valores dos pixels)\n",
    "        brilho = np.mean(gray)\n",
    "\n",
    "        # Calcular contraste\n",
    "        contraste = gray.std()\n",
    "\n",
    "        # Contar faces na imagem (usando um modelo pré-treinado do OpenCV)\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "        qtd_faces = len(faces)\n",
    "\n",
    "        # Extrair cor predominante\n",
    "        pixels = img_cv.reshape(-1, 3)\n",
    "        cor_predominante = np.mean(pixels, axis=0).mean()\n",
    "\n",
    "        return brilho, contraste, cor_predominante, qtd_faces\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar a imagem: {e}\")\n",
    "        return None, None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   likes  comments  duration_sec  year  month  day  weekday  likes_per_view  \\\n",
      "0      0         0          1700  2025      2    4        0               0   \n",
      "\n",
      "   comments_per_view  title_word_count  ...  tortuguita  treinar  um  usar  \\\n",
      "0                  0                 9  ...           0        0   0     0   \n",
      "\n",
      "   você  vs    brilho  contraste  cor_predominante  qtd_faces  \n",
      "0     0   0  84.65458  77.445994         84.455341          3  \n",
      "\n",
      "[1 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 🚀 Caminho da imagem no seu PC (exemplo)\n",
    "caminho_thumb = \"/Users/luisfelipesouzacardoso/Documents/Estudo/Data_Science/fdm_analytics/250129_defesa-pessoal-mulheresjpg.jpg\"  # Substitua pelo caminho real\n",
    "\n",
    "# 🚀 Analisar a thumbnail carregada do PC\n",
    "brilho, contraste, cor_predominante, qtd_faces = analisar_thumbnail_local(caminho_thumb)\n",
    "\n",
    "# 🚀 Atualizar `novo_video` com as features extraídas automaticamente\n",
    "novo_video[\"brilho\"] = brilho\n",
    "novo_video[\"contraste\"] = contraste\n",
    "novo_video[\"cor_predominante\"] = cor_predominante\n",
    "novo_video[\"qtd_faces\"] = qtd_faces\n",
    "\n",
    "# Exibir o DataFrame atualizado\n",
    "print(novo_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  duration_sec  year  \\\n",
      "0  Leo Stronda e Scarpelly | Fala Monstro Talk Sh...          1700  2025   \n",
      "\n",
      "   month  day  weekday  likes  comments  likes_per_view  comments_per_view  \\\n",
      "0      2    4  Tuesday      0         0               0                  0   \n",
      "\n",
      "   title_word_count  qtd_palavras_thumb  media_views_ultimos_10  \\\n",
      "0                10                   3                 39720.9   \n",
      "\n",
      "   media_likes_per_view  media_comments_per_view  \\\n",
      "0                   0.1                     0.02   \n",
      "\n",
      "                                  qtd_palavras_nicho    brilho  contraste  \\\n",
      "0  [treino, hipertrofia, massa muscular, exercíci...  84.65458  77.445994   \n",
      "\n",
      "   cor_predominante  qtd_faces  \n",
      "0         84.455341          3  \n"
     ]
    }
   ],
   "source": [
    "# Definir o título do novo vídeo\n",
    "titulo_novo_video = \"Leo Stronda e Scarpelly | Fala Monstro Talk Show #01\"\n",
    "\n",
    "# 🚀 Calcular automaticamente a média de views dos últimos 10 vídeos\n",
    "media_views_ultimos_10 = df_videos[\"views\"].rolling(window=10, min_periods=1).mean().iloc[-1]\n",
    "\n",
    "\n",
    "# 🚀 Criar o DataFrame do novo vídeo com todas as features\n",
    "novo_video = pd.DataFrame({\n",
    "    \"title\": [titulo_novo_video],  \n",
    "    \"duration_sec\": [1700],  \n",
    "    \"year\": [2025],\n",
    "    \"month\": [2],\n",
    "    \"day\": [4],\n",
    "    \"weekday\": [\"Tuesday\"],  \n",
    "    \"likes\": [0],  \n",
    "    \"comments\": [0],\n",
    "    \"likes_per_view\": [0],\n",
    "    \"comments_per_view\": [0],\n",
    "    \"title_word_count\": [len(titulo_novo_video.split())],  \n",
    "    \"qtd_palavras_thumb\": [3],  \n",
    "    \"media_views_ultimos_10\": [media_views_ultimos_10],  \n",
    "    \"media_likes_per_view\": [0.1],\n",
    "    \"media_comments_per_view\": [0.02],\n",
    "    \"qtd_palavras_nicho\": [palavras_chave_nicho ]  \n",
    "})\n",
    "\n",
    "# 🚀 Adicionar os valores da thumbnail analisada\n",
    "novo_video[\"brilho\"] = brilho\n",
    "novo_video[\"contraste\"] = contraste\n",
    "novo_video[\"cor_predominante\"] = cor_predominante\n",
    "novo_video[\"qtd_faces\"] = qtd_faces\n",
    "\n",
    "# Exibir o DataFrame atualizado para verificar\n",
    "print(novo_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Novo vídeo formatado para previsão: 110 features\n",
      "✅ Novo vídeo formatado para previsão: 110 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d6/gf2wlh6x083f9l84m7czsqbw0000gn/T/ipykernel_84282/4090742985.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  novo_video[col] = 0  # Adicionar colunas faltantes com valor 0\n",
      "/var/folders/d6/gf2wlh6x083f9l84m7czsqbw0000gn/T/ipykernel_84282/4090742985.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  novo_video[col] = 0  # Adicionar colunas faltantes com valor 0\n",
      "/var/folders/d6/gf2wlh6x083f9l84m7czsqbw0000gn/T/ipykernel_84282/4090742985.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  novo_video[col] = 0  # Adicionar colunas faltantes com valor 0\n",
      "/var/folders/d6/gf2wlh6x083f9l84m7czsqbw0000gn/T/ipykernel_84282/4090742985.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  novo_video[col] = 0  # Adicionar colunas faltantes com valor 0\n",
      "/var/folders/d6/gf2wlh6x083f9l84m7czsqbw0000gn/T/ipykernel_84282/4090742985.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  novo_video[col] = 0  # Adicionar colunas faltantes com valor 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 🚀 Verificar se a coluna \"weekday\" existe no novo_video\n",
    "if \"weekday\" in novo_video.columns:\n",
    "    novo_video = pd.get_dummies(novo_video, columns=[\"weekday\"])\n",
    "else:\n",
    "    print(\"⚠️ A coluna 'weekday' não está presente. Criando colunas manualmente.\")\n",
    "\n",
    "    # Criar colunas one-hot encoding manualmente (todas zeradas por padrão)\n",
    "    for dia in [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]:\n",
    "        novo_video[f\"weekday_{dia}\"] = 0\n",
    "\n",
    "    # Definir o dia correto como 1\n",
    "    novo_video[f\"weekday_Monday\"] = 1  # Ajuste conforme o dia real do vídeo\n",
    "\n",
    "# 🚀 Garantir que todas as colunas do treinamento estão presentes\n",
    "for col in X_train.columns:\n",
    "    if col not in novo_video.columns:\n",
    "        novo_video[col] = 0  # Adicionar colunas faltantes com valor 0\n",
    "\n",
    "# 🚀 Reordenar as colunas para corresponder ao treinamento\n",
    "novo_video = novo_video[X_train.columns]\n",
    "\n",
    "# 🚀 Converter para valores numéricos\n",
    "novo_video = novo_video.apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "\n",
    "print(f\"✅ Novo vídeo formatado para previsão: {novo_video.shape[1]} features\")\n",
    "\n",
    "\n",
    "# 🚀 Converter o dia da semana para one-hot encoding\n",
    "novo_video = pd.get_dummies(novo_video, columns=[\"weekday\"])\n",
    "\n",
    "# Garantir que todas as colunas do treinamento estão presentes\n",
    "for col in X_train.columns:\n",
    "    if col not in novo_video.columns:\n",
    "        novo_video[col] = 0  # Adicionar colunas faltantes com valor 0\n",
    "\n",
    "# Reordenar as colunas para corresponder ao treinamento\n",
    "novo_video = novo_video[X_train.columns]\n",
    "\n",
    "# Converter para valores numéricos\n",
    "novo_video = novo_video.apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "\n",
    "print(f\"✅ Novo vídeo formatado para previsão: {novo_video.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Novo vídeo formatado para previsão: 110 features\n"
     ]
    }
   ],
   "source": [
    "# 🚀 Converter o dia da semana para one-hot encoding\n",
    "novo_video = pd.get_dummies(novo_video, columns=[\"weekday\"])\n",
    "\n",
    "# Garantir que todas as colunas do treinamento estão presentes\n",
    "for col in X_train.columns:\n",
    "    if col not in novo_video.columns:\n",
    "        novo_video[col] = 0  # Adicionar colunas faltantes com valor 0\n",
    "\n",
    "# Reordenar as colunas para corresponder ao treinamento\n",
    "novo_video = novo_video[X_train.columns]\n",
    "\n",
    "# Converter tudo para valores numéricos\n",
    "novo_video = novo_video.apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "\n",
    "# ✅ Exibir a estrutura do novo vídeo\n",
    "print(f\"✅ Novo vídeo formatado para previsão: {novo_video.shape[1]} features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Previsão de Visualizações: 12193\n"
     ]
    }
   ],
   "source": [
    "# 🚀 Converter para DataFrame e garantir que as colunas estão corretas\n",
    "novo_video_df = pd.DataFrame(novo_video, columns=X_train.columns)\n",
    "\n",
    "# 🚀 Converter para NumPy apenas na previsão para evitar warnings\n",
    "novo_video_array = novo_video_df.to_numpy()\n",
    "\n",
    "# 🚀 Fazer a previsão corretamente\n",
    "previsao_visualizacoes = modelo_rf.predict(novo_video_array)  # Agora passa um array puro\n",
    "\n",
    "# 📊 Exibir a previsão\n",
    "print(f\"📊 Previsão de Visualizações: {int(previsao_visualizacoes[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
